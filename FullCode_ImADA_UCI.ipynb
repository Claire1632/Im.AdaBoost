{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import trainning_of_adaboost as toa\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import adaboost_svm, ImAda_DecisionTree\n",
    "from sklearn.metrics  import classification_report, precision_recall_fscore_support as score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score, precision_score\n",
    "import math\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from wsvm.application import Wsvm\n",
    "from sklearn.svm import SVC\n",
    "# from fuzzy.weight import fuzzy\n",
    "# from keras.models import Sequential \n",
    "# from keras.layers import Dense,Activation,Dropout \n",
    "# from keras.utils import np_utils\n",
    "# from keras.utils import to_categorical\n",
    "# from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_test,y_pred):\n",
    "    cm_WSVM = confusion_matrix(y_test, y_pred)\n",
    "    se = cm_WSVM[1,1]/(cm_WSVM[1,0]+cm_WSVM[1,1])\n",
    "    sp = cm_WSVM[0,0]/(cm_WSVM[0,0]+cm_WSVM[0,1])\n",
    "    gmean = math.sqrt(se*sp)\n",
    "    f1s = f1_score(y_test,y_pred)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    pre = precision_score(y_test,y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    return sp, se, gmean, f1s, pre, acc, auc, cm_WSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SVM lib\n",
    "def svm_lib(X_train, y_train,X_test):\n",
    "    clf = SVC(probability=True, kernel='linear')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SVM hand\n",
    "# def svm(C,X_train, y_train,X_test):\n",
    "#     model = Svm(C)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     test_pred = model.predict(X_test)\n",
    "#     return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DecisionTree\n",
    "from sklearn import tree\n",
    "def decisiontree(X_train, y_train,X_test):\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. WSVM\n",
    "def wsvm(C,X_train, y_train,X_test,distribution_weight=None):\n",
    "    model = Wsvm(C,distribution_weight)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. AdaBoost SVM\n",
    "# def ada_svm(M, C, X_train, y_train, X_test, theta):\n",
    "#     w, b, a = adaboost_svm.fit(X_train, y_train, M, C, instance_categorization=False, proposed = False, theta=theta)\n",
    "#     y_pred = adaboost_svm.predict(X_test, w, b, a, M)\n",
    "#     return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. AdaBoost SVM\n",
    "def ada_svm(M, X_train, y_train, X_test):\n",
    "    clf = AdaBoostClassifier(n_estimators = M, base_estimator=SVC(probability=True,kernel='linear'), learning_rate=1.0, algorithm='SAMME')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. AdaBoost DecisionTree\n",
    "def ada_decisiontree(M, X_train, y_train,X_test):\n",
    "    clf = AdaBoostClassifier(n_estimators=M)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. AdaBoost WSVM\n",
    "def ada_wsvm(M, C, theta, X_train, y_train,X_test):\n",
    "    w, b, a = toa.fit(X_train, y_train, M, C, instance_categorization=True, proposed_preprocessing = False,proposed_alpha = False, test_something = False, theta=theta)\n",
    "    y_pred = toa.predict(X_test, w, b, a, M)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. IM.AdaBoost-1 WSVM\n",
    "def imada1_wsvm(M, C, theta, X_train, y_train,X_test):\n",
    "    w, b, a = toa.fit(X_train, y_train, M, C, instance_categorization=True, proposed_preprocessing = True, proposed_alpha = False, test_something = False, theta=theta)\n",
    "    y_pred = toa.predict(X_test, w, b, a, M)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. IM.AdaBoost-2 WSVM\n",
    "def imada2_wsvm(M, C, X_train, y_train,X_test):\n",
    "    w, b, a= toa.fit(X_train, y_train, M, C, instance_categorization = True,proposed_preprocessing = False,proposed_alpha=True,test_something = False)\n",
    "    y_pred = toa.predict(X_test, w, b, a, M)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. IM.AdaBoost-12 WSVM\n",
    "def imada_12_wsvm(M, C, theta, X_train, y_train,X_test):\n",
    "    w, b, a = toa.fit(X_train, y_train, M, C, instance_categorization = True,proposed_preprocessing= True,proposed_alpha=True,test_something = False, theta=theta)\n",
    "    y_pred = toa.predict(X_test, w, b, a, M)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. IM.AdaBoost1 + SVM\n",
    "def imada1_svm(M, C, theta, X_train, y_train,X_test):\n",
    "    w, b, a = toa.fit(X_train, y_train, M, C, instance_categorization = False, proposed_preprocessing= True,proposed_alpha=False,test_something = True, theta=theta)\n",
    "    y_pred = toa.predict(X_test, w, b, a, M)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. IM.AdaBoost2 + SVM\n",
    "def imada2_svm(M, C, X_train, y_train,X_test):\n",
    "    w, b, a = toa.fit(X_train, y_train, M, C, instance_categorization = False,proposed_preprocessing = False,proposed_alpha=True,test_something = True)\n",
    "    y_pred = toa.predict(X_test, w, b, a, M)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13. IM.AdaBoost12 + SVM\n",
    "def imada_12_svm(M, C, theta, X_train, y_train,X_test):\n",
    "    w, b, a = toa.fit(X_train, y_train, M, C, instance_categorization = False,proposed_preprocessing= True,proposed_alpha=True,test_something = True, theta=theta)\n",
    "    y_pred = toa.predict(X_test, w, b, a, M)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imada_1_decisiontree(M,theta,X_train, y_train,X_test):\n",
    "    clf, a = ImAda_DecisionTree.fit(X_train, y_train, M, proposed_preprocessing = True, proposed_alpha = False, theta = theta)\n",
    "    y_pred = ImAda_DecisionTree.predict(X_test, a, clf)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imada_2_decisiontree(M, X_train, y_train,X_test):\n",
    "    clf, a = ImAda_DecisionTree.fit(X_train, y_train, M, proposed_preprocessing = False, proposed_alpha = True)\n",
    "    y_pred = ImAda_DecisionTree.predict(X_test, a, clf)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imada_12_decisiontree(M,theta,X_train, y_train,X_test):\n",
    "    clf, a = ImAda_DecisionTree.fit(X_train, y_train, M, proposed_preprocessing = True, proposed_alpha = True, theta = theta)\n",
    "    y_pred = ImAda_DecisionTree.predict(X_test, a, clf)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight(X, y,name_method =\"actual_hyper_lin\", name_function = \"exp\", beta = None,C = None, gamma = None, u = None, sigma = None):\n",
    "    method = fuzzy.method()\n",
    "    function = fuzzy.function()\n",
    "    pos_index = np.where(y == 1)[0]\n",
    "    neg_index = np.where(y == -1)[0]\n",
    "    try:\n",
    "        if name_method == \"own_class_center\": \n",
    "            d = method.own_class_center(X, y)\n",
    "        elif name_method == \"estimated_hyper_lin\": # actual_hyper_lin, own_class_center\n",
    "            d = method.estimated_hyper_lin(X, y)\n",
    "        elif name_method == \"own_class_center_opposite\":\n",
    "            d = method.own_class_center_opposite(X, y)\n",
    "        elif name_method == 'actual_hyper_lin':\n",
    "            d = method.actual_hyper_lin(X, y,C = C, gamma = gamma)\n",
    "        elif name_method == 'own_class_center_divided':\n",
    "            d = method.own_class_center_divided(X, y)\n",
    "        elif name_method == \"distance_center_own_opposite_tam\":\n",
    "            d_own, d_opp, d_tam = method.distance_center_own_opposite_tam(X,y)\n",
    "        else:\n",
    "            print('dont exist method')\n",
    "        \n",
    "        if name_function == \"lin\":\n",
    "            W = function.lin(d)\n",
    "        elif name_function == \"exp\":\n",
    "            W = function.exp(d, beta)\n",
    "        elif name_function == \"lin_center_own\":\n",
    "            W = function.lin_center_own(d, pos_index,neg_index)\n",
    "        elif name_function == 'gau':\n",
    "            W = function.gau(d, u, sigma)\n",
    "        elif name_function == \"func_own_opp_new\":\n",
    "            W = function.func_own_opp_new(d_own,d_opp,pos_index,neg_index,d_tam)\n",
    "        elif name_function == \"func_own_opp_new_v1\":\n",
    "            W = function.func_own_opp_new_v1(d_own,d_opp,pos_index,neg_index,d_tam)\n",
    "        elif name_function == \"func_own_opp_new_v2\":\n",
    "            W = function.func_own_opp_new_v2(d_own,d_opp,pos_index,neg_index,d_tam)\n",
    "    except Exception as e:\n",
    "        print('dont exist function')\n",
    "        print(e)\n",
    "    # pos_index = np.where(y == 1)[0]\n",
    "    # neg_index = np.where(y == -1)[0]\n",
    "    r_pos = 1\n",
    "    r_neg = len(pos_index)/len(neg_index)\n",
    "    m = []\n",
    "    W = np.array(W)\n",
    "    m = W[pos_index]*r_pos\n",
    "    m = np.append(m, W[neg_index]*r_neg)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_weight(beta_center, beta_estimate, beta_actual,X_train, y_train,namemethod,namefunction):\n",
    "    if namemethod ==\"own_class_center_opposite\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_center)\n",
    "    elif namemethod ==\"own_class_center\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_estimate)\n",
    "    elif namemethod ==\"own_class_center_divided\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_estimate)\n",
    "    elif namemethod ==\"estimated_hyper_lin\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_estimate)\n",
    "    elif namemethod ==\"actual_hyper_lin\" and namefunction == \"exp\":\n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction,beta = beta_actual)\n",
    "    else:   \n",
    "        distribution_weight = compute_weight(X_train, y_train,name_method = namemethod,name_function = namefunction)\n",
    "    return distribution_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(X_train, train_labels, X_test, test_labels):\n",
    "    model=Sequential()\n",
    "    # model.add(Dense(1000,input_dim=7,activation='relu')) #Ecoli\n",
    "    # model.add(Dense(1000,input_dim=3,activation='relu')) #Haberman\n",
    "    # model.add(Dense(1000,input_dim=4,activation='relu')) #Transfusion\n",
    "    model.add(Dense(1000,input_dim=7,activation='relu')) #Co-Author\n",
    "    # model.add(Dense(1000,input_dim=8,activation='relu')) #Abalone\n",
    "    # model.add(Dense(1000,input_dim=10,activation='relu')) #Page-blocks\n",
    "    # model.add(Dense(1000,input_dim=36,activation='relu')) #Satimage\n",
    "    # model.add(Dense(1000,input_dim=8,activation='relu')) #Yeast, Pima\n",
    "    model.add(Dense(500,activation='relu'))\n",
    "    model.add(Dense(300,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    # model.fit(X_train,train_labels,validation_data=(X_test,test_labels),batch_size=20,epochs=10,verbose=1)\n",
    "    model.fit(X_train,train_labels,validation_data=(X_test,test_labels),batch_size=20,epochs=10,verbose=2)\n",
    "    prediction = model.predict(X_test)\n",
    "    y_label=np.argmax(test_labels,axis=1)\n",
    "    predict_label=np.argmax(prediction,axis=1)\n",
    "    sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_label,predict_label)\n",
    "    return sp, se, gmean, f1s, pre, acc, auc, cm_WSVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lan boc:  1\n",
      "Decision Tree starting...\n",
      "\n",
      "SVM (lib) starting...\n",
      "\n",
      "WSVM starting...\n",
      "\n",
      "C =  10000\n",
      "ADA_Decision Tree starting...\n",
      "\n",
      "M =  10\n",
      "ADA_SVM starting...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\APP\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA_WSVM starting...\n",
      "\n",
      "C =  10000\n",
      "M =  10\n",
      "Im.AdaBoost2.DecisionTree starting...\n",
      "\n",
      "theta =  0.2\n",
      "ImADA_1_DecisionTree starting...\n",
      "\n",
      "ImADA_12_DecisionTree starting...\n",
      "\n",
      "10 10000 0.2\n",
      "ImADA1_SVM starting...\n",
      "\n",
      "ImADA2_SVM starting...\n",
      "\n",
      "ImADA_12_SVM starting...\n",
      "\n",
      "ImADA1_WSVM starting...\n",
      "\n",
      "ImADA2_WSVM starting...\n",
      "\n",
      "ImADA_12_WSVM starting...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################################### TEST SIZE SCRIPT - FIND BEST PARAMETERS - CHANGE RATE - FINAL ################################\n",
    "\n",
    "from data import Ecoli_TestSize, Transfution_TestSize, Yeast_TestSize, Abanole_TestSize\n",
    "\n",
    "#Test\n",
    "M = [10]\n",
    "C = [10000]\n",
    "theta = [0.2, 0.5, 0.8, 1.1, 1.4, 1.7, 2]\n",
    "N = 5\n",
    "test_size = [0.3]\n",
    "\n",
    "dataset = Ecoli_TestSize\n",
    "time = datetime.now().strftime(\"%d%m%Y_%H%M%S\")\n",
    "filename = (str(dataset).split(\"\\\\\")[-1]).split(\".\")[0]\n",
    "filepath = f'./Experiment/Data_{filename}_TestSize.csv'\n",
    "for n in range(0,N):\n",
    "    header = ['Test Size','Name Method','M','C','theta','SP', 'SE', 'Gmean', 'F1 Score','Precision','Accuracy','AUC','Ma tran nham lan']\n",
    "    data = []\n",
    "    print(\"Lan boc: \", n+1)\n",
    "    with open(f'./Experiment/Data_{filename}_{time}_TestSize.csv', 'a', encoding='UTF8', newline='') as f1:\n",
    "        writer = csv.writer(f1)\n",
    "        writer.writerow(header)\n",
    "        for testsize in test_size:\n",
    "                \n",
    "            X_train, y_train, X_test, y_test = dataset.load_data(test_size=testsize)  \n",
    "      \n",
    "            #No 1\n",
    "            print(\"Decision Tree starting...\\n\")\n",
    "            y_pred = decisiontree(X_train, y_train, X_test)\n",
    "            sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "            name = \"Decision Tree\"\n",
    "            m = \"None\"\n",
    "            c = \"None\"\n",
    "            t = \"None\"\n",
    "            writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "\n",
    "\n",
    "            #No 2\n",
    "            print(\"SVM (lib) starting...\\n\")\n",
    "            y_pred = svm_lib(X_train, y_train, X_test)\n",
    "            sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "            name = \"SVM\"\n",
    "            m = \"None\"\n",
    "            c = \"None\"\n",
    "            t = \"None\"\n",
    "            writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "\n",
    "            # #No 3\n",
    "            # print(\"CNN starting...\\n\")\n",
    "            # sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = neural_network(X_train_1, train_labels, X_test_1, test_labels)\n",
    "            # name = 'CNN'\n",
    "            # m = \"None\"\n",
    "            # c = \"None\"\n",
    "            # t = \"None\"\n",
    "            # writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "\n",
    "\n",
    "            # No 4\n",
    "            for c in C:\n",
    "                print(\"WSVM starting...\\n\")\n",
    "                print(\"C = \", c)\n",
    "                N, d = X_train.shape\n",
    "                distribution_weight = np.ones(N)\n",
    "                y_pred = wsvm(c,X_train, y_train,X_test,distribution_weight)\n",
    "                sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "                name = \"WSVM\"\n",
    "                m = \"None\"\n",
    "                t = \"None\"\n",
    "                writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "\n",
    "            \n",
    "            for m in M:\n",
    "                #No 5\n",
    "                print(\"ADA_Decision Tree starting...\\n\")\n",
    "                print(\"M = \", m)\n",
    "                y_pred = ada_decisiontree(m,X_train, y_train, X_test)\n",
    "                sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "                name = 'ADABoost.DecisionTree'\n",
    "                c = \"None\"\n",
    "                t = \"None\"\n",
    "                writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "\n",
    "\n",
    "                #No 6\n",
    "                print(\"ADA_SVM starting...\\n\")\n",
    "                y_pred = ada_svm(m, X_train, y_train, X_test)\n",
    "                sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "                name = 'ADABoost.SVM'\n",
    "                c = \"None\"\n",
    "                t = \"None\"\n",
    "                writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "            \n",
    "\n",
    "                for c in C:\n",
    "                    #No 7\n",
    "                    print(\"ADA_WSVM starting...\\n\")\n",
    "                    print(\"C = \",c)\n",
    "                    t = 1\n",
    "                    y_pred = ada_wsvm(m, c, t, X_train, y_train,X_test)\n",
    "                    sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "                    name = 'ADABoost.W-SVM'\n",
    "                    writer.writerow([testsize,name,m,c,\"None\",sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "\n",
    "            for m in M:\n",
    "                print(\"M = \", m)\n",
    "                #No 9\n",
    "                print(\"Im.AdaBoost2.DecisionTree starting...\\n\")\n",
    "                y_pred = imada_2_decisiontree(m, X_train, y_train,X_test)\n",
    "                sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "                name = 'Im.AdaBoost.DecisionTree.2'\n",
    "                c = \"None\"\n",
    "                t = \"None\"\n",
    "                writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "\n",
    "\n",
    "                for t in theta:\n",
    "                    print(\"theta = \",t)\n",
    "                    #No 8\n",
    "                    print(\"ImADA_1_DecisionTree starting...\\n\")\n",
    "                    c = \"None\"\n",
    "                    y_pred = imada_1_decisiontree(m, t, X_train, y_train,X_test)\n",
    "                    sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "                    name = 'Im.AdaBoost.DecisionTree.1'\n",
    "                    writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "\n",
    "\n",
    "                    #No 10\n",
    "                    print(\"ImADA_12_DecisionTree starting...\\n\")\n",
    "                    y_pred = imada_12_decisiontree(m, t, X_train, y_train,X_test)\n",
    "                    sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "                    c = \"None\"\n",
    "                    name = 'Im.AdaBoost.DecisionTree.12'\n",
    "                    writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "\n",
    "            for m in M:\n",
    "                for c in C:\n",
    "                    for t in theta:\n",
    "                        print(m,c,t)\n",
    "                        #No 11\n",
    "                        print(\"ImADA1_SVM starting...\\n\")\n",
    "                        y_pred = imada1_svm(m, c, t, X_train, y_train,X_test)\n",
    "                        sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "                        name = 'Im.ADABoost.SVM.1'\n",
    "                        writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "\n",
    "                        #No 12\n",
    "                        print(\"ImADA2_SVM starting...\\n\")\n",
    "                        y_pred = imada2_svm(m, c, X_train, y_train,X_test)\n",
    "                        sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "                        name = 'Im.ADABoost.SVM.2'\n",
    "                        writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "\n",
    "                        #No 13\n",
    "                        print(\"ImADA_12_SVM starting...\\n\")\n",
    "                        y_pred = imada_12_svm(m, c,t, X_train, y_train,X_test)\n",
    "                        sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "                        name = 'Im.ADABoost.SVM.12'\n",
    "                        writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "\n",
    "                        #No 14\n",
    "                        print(\"ImADA1_WSVM starting...\\n\")\n",
    "                        y_pred = imada1_wsvm(m, c, t, X_train, y_train,X_test)\n",
    "                        sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "                        name = 'Im.ADABoost.W-SVM.1'\n",
    "                        writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "\n",
    "                        #No 15\n",
    "                        print(\"ImADA2_WSVM starting...\\n\")\n",
    "                        y_pred = imada2_wsvm(m, c, X_train, y_train,X_test)\n",
    "                        sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "                        name = 'Im.ADABoost.W-SVM.2'\n",
    "                        writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])       \n",
    "\n",
    "                        #No 16\n",
    "                        print(\"ImADA_12_WSVM starting...\\n\")\n",
    "                        y_pred = imada_12_wsvm(m, c, t, X_train, y_train,X_test)\n",
    "                        sp, se, gmean, f1s, pre, acc, auc, cm_WSVM = compute_metrics(y_test, y_pred)\n",
    "                        name = 'Im.ADABoost.W-SVM.12'\n",
    "                        writer.writerow([testsize,name,m,c,t,sp, se, gmean, f1s, pre, acc, auc, str(cm_WSVM)])\n",
    "        f1.close()  \n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('FSVM-CIL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd073cf77417f2eda899b4964833636dfa63b2ff098a61069509a2b01c748e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
